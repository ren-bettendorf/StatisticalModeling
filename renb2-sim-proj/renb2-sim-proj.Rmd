---
title: "Simulation Project"
author: "Ren Bettendorf, renb2"
date: "6/12/2019"
output: html_document
---

## Simulation Study 1: Significance of Regression


### **Introduction**
<br />
In this Simulation Study we are given two models to investigate the significance of regression which we will name "**Significant**" and "**Non-Significant**".
<br />

* **Significant Model**
  -  $Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \epsilon_i$
  -  $\beta_0 = 3$
  -  $\beta_1 = 1$
  -  $\beta_2 = 1$
  -  $\beta_3 = 1$
  -  $\epsilon_i \sim N(0, \sigma^2)$
<br />

* **Non-Significant Model**
  + $Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \epsilon_i$
  + $\beta_0 = 3$
  + $\beta_1 = 0$
  + $\beta_2 = 0$
  + $\beta_3 = 0$
  + $\epsilon_i \sim N(0, \sigma^2)$
<br />

What we mean by investigate the significance of regression is to investigate the given predictors $x_1, x_2, x_3$ and to determine if there is a linear relationship when considering these variables with $Y$. In order to show if this relationship exists though we will be doing $2,500$ simulations based upon data contained in `study_1.csv` with a sample size of $25$ with the following $\sigma \in (1, 5, 10)$ which leads to a total of $15,000$ simulations for our $Y$ variable. For comparison at the end we will consider the $F statistic$, $p-value$, and $R^2$ to determine which empirical distribution.
<br />

### **Methods**
```{r setup_model_1, message=FALSE, warning=FALSE, cache=TRUE}
birthday = 19890927
set.seed(birthday)
library(readr)
study_1_data = read_csv("study_1.csv")
n = 25
p = 3 + 1
x0 = rep(1, n)
x1 = study_1_data$x1
x2 = study_1_data$x2
x3 = study_1_data$x3

# Significant Model beta values
sig_beta_0 = 3
sig_beta_1 = 1
sig_beta_2 = 1
sig_beta_3 = 1
# Non-Significant Model beta values
non_beta_0 = 3
non_beta_1 = 0
non_beta_2 = 0
non_beta_3 = 0

sigma = c(1, 5, 10)
simulations = 2500
```

```{r simulate_model_1, cache=TRUE}
sim1_data = data.frame(sig_f = rep(0, simulations), sig_p = rep(0, simulations), sig_r = rep(0, simulations),
                       non_f = rep(0, simulations), non_p = rep(0, simulations), non_r = rep(0, simulations))
for (iter in 1:simulations) {
  eps = rnorm(n, mean = 0, sd = sigma[1])
  study_1_data$y = sig_beta_0 + sig_beta_1 * x1 + sig_beta_2 * x2 + sig_beta_3 * x3 + eps
  sig_model = lm(y ~ ., data = study_1_data)
  sim1_data$sig_f[iter] = summary(sig_model)$fstatistic[[1]]
  sim1_data$sig_p[iter] = pf(summary(sig_model)$fstatistic[[1]], df1 = p - 1, df2 = n - p, lower.tail = FALSE)
  sim1_data$sig_r[iter] = summary(sig_model)$r.squared
  
  study_1_data$y = non_beta_0 + non_beta_1 * x1 + non_beta_2 * x2 + non_beta_3 * x3 + eps
  non_model = lm(y ~ ., data = study_1_data)
  sim1_data$non_f[iter] = summary(non_model)$fstatistic[[1]]
  sim1_data$non_p[iter] = pf(summary(non_model)$fstatistic[[1]], df1 = p - 1, df2 = n - p, lower.tail = FALSE)
  sim1_data$non_r[iter] = summary(non_model)$r.squared
}

sim2_data = data.frame(sig_f = rep(0, simulations), sig_p = rep(0, simulations), sig_r = rep(0, simulations),
                       non_f = rep(0, simulations), non_p = rep(0, simulations), non_r = rep(0, simulations))
for (iter in 1:simulations) {
  eps = rnorm(n, mean = 0, sd = sigma[2])
  study_1_data$y = sig_beta_0 + sig_beta_1 * x1 + sig_beta_2 * x2 + sig_beta_3 * x3 + eps
  sig_model = lm(y ~ ., data = study_1_data)
  sim2_data$sig_f[iter] = summary(sig_model)$fstatistic[[1]]
  sim2_data$sig_p[iter] = pf(summary(sig_model)$fstatistic[[1]], df1 = p - 1, df2 = n - p, lower.tail = FALSE)
  sim2_data$sig_r[iter] = summary(sig_model)$r.squared
  
  study_1_data$y = non_beta_0 + non_beta_1 * x1 + non_beta_2 * x2 + non_beta_3 * x3 + eps
  non_model = lm(y ~ ., data = study_1_data)
  sim2_data$non_f[iter] = summary(non_model)$fstatistic[[1]]
  sim2_data$non_p[iter] = pf(summary(non_model)$fstatistic[[1]], df1 = p - 1, df2 = n - p, lower.tail = FALSE)
  sim2_data$non_r[iter] = summary(non_model)$r.squared
}

sim3_data = data.frame(sig_f = rep(0, simulations), sig_p = rep(0, simulations), sig_r = rep(0, simulations),
                       non_f = rep(0, simulations), non_p = rep(0, simulations), non_r = rep(0, simulations))
for (iter in 1:simulations) {
  eps = rnorm(n, mean = 0, sd = sigma[3])
  study_1_data$y = sig_beta_0 + sig_beta_1 * x1 + sig_beta_2 * x2 + sig_beta_3 * x3 + eps
  sig_model = lm(y ~ ., data = study_1_data)
  sim3_data$sig_f[iter] = summary(sig_model)$fstatistic[[1]]
  sim3_data$sig_p[iter] = pf(summary(sig_model)$fstatistic[[1]], df1 = p - 1, df2 = n - p, lower.tail = FALSE)
  sim3_data$sig_r[iter] = summary(sig_model)$r.squared
  
  study_1_data$y = non_beta_0 + non_beta_1 * x1 + non_beta_2 * x2 + non_beta_3 * x3 + eps
  non_model = lm(y ~ ., data = study_1_data)
  sim3_data$non_f[iter] = summary(non_model)$fstatistic[[1]]
  sim3_data$non_p[iter] = pf(summary(non_model)$fstatistic[[1]], df1 = p - 1, df2 = n - p, lower.tail = FALSE)
  sim3_data$non_r[iter] = summary(non_model)$r.squared
}
```

###  **Results**
###  **Discussion**

## Simulation Study 2: Using RMSE for Selection?

###  **Introduction**
<br />
In this Simulation Study we will be looking at RMSE, root mean sequared error, when considering multiple models and will use simulation to determine if our selected model is the actual **best** model. The model we have selected to model is

* $Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \beta_4 x_{i4} + \beta_5 x_{i5} + \beta_6 x_{i6} + \epsilon_i$
  +  $\beta_0 = 0$
  +  $\beta_1 = 5$
  +  $\beta_2 = -4$
  +  $\beta_3 = 1.6$
  +  $\beta_4 = -1.1$
  +  $\beta_5 = 0.7$
  +  $\beta_6 = 0.3$
  +  $\epsilon_i \sim N(0, \sigma^2)$ where $\sigma \in (1, 2, 4)$
<br />

From this model we will fit the following models

* $y \sim x1$
* $y \sim x1 + x2$
* $y \sim x1 + x2 + x3$
* $y \sim x1 + x2 + x3 + x4$
* $y \sim x1 + x2 + x3 + x4 + x5$
* $y \sim x1 + x2 + x3 + x4 + x5 + x6$
* $y \sim x1 + x2 + x3 + x4 + x5 + x6 + x7$
* $y \sim x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8$
* $y \sim x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9$
<br />

The data contained in `study_2.csv` consists of $500$ observations which we will split in half randomly each for a training and a testing dataset which we will run $1000$ times for each value of $\sigma$ which totals $3,000$ simulations and $27,000$ models trained.

###  **Methods**
```{r setup_simulate_2, message=FALSE, warning=FALSE, cache=TRUE}
birthday = 19890927
set.seed(birthday)
library(readr)
study_2_data = read_csv("study_2.csv")
n = nrow(study_2_data)
p = 3 + 1
x0 = rep(1, n)
x1 = study_2_data$x1
x2 = study_2_data$x2
x3 = study_2_data$x3
x4 = study_2_data$x4
x5 = study_2_data$x5
x6 = study_2_data$x6
sigma = c(1, 2, 4)

beta_0 = 0
beta_1 = 5
beta_2 = -4
beta_3 = 1.6
beta_4 = -1.1
beta_5 = 0.7
beta_6 = 0.3

simulations = 1000

calculate_rmse  = function(actual, predicted) {
  return(sqrt(mean((actual - predicted)^2)))
}
```
```{r simulate_models_2, cache=TRUE}
sim1_rmse_train = data.frame(model_1 = rep(0, simulations), model_2 = rep(0, simulations), model_3 = rep(0, simulations),
                             model_4 = rep(0, simulations), model_5 = rep(0, simulations), model_6 = rep(0, simulations),
                             model_7 = rep(0, simulations), model_8 = rep(0, simulations), model_9 = rep(0, simulations))
sim1_rmse_test = data.frame(model_1 = rep(0, simulations), model_2 = rep(0, simulations), model_3 = rep(0, simulations),
                            model_4 = rep(0, simulations), model_5 = rep(0, simulations), model_6 = rep(0, simulations),
                            model_7 = rep(0, simulations), model_8 = rep(0, simulations), model_9 = rep(0, simulations))
for (iter in 1:simulations) {
  eps = rnorm(n, mean = 0, sd = sigma[1])
  study_2_data$y = beta_0 + beta_1 * x1 +  beta_2 * x2 + beta_3 * x3 + beta_4 * x4 + beta_5 * x5 + beta_6 * x6 + eps
  
  train_index = sample(n / 2)
  train_data = study_2_data[train_index,]
  test_data = study_2_data[-train_index,]
  
  model_1 = lm(y ~ x1, data = train_data)
  model_2 = lm(y ~ x1 + x2, data = train_data)
  model_3 = lm(y ~ x1 + x2 + x3, data = train_data)
  model_4 = lm(y ~ x1 + x2 + x3 + x4, data = train_data)
  model_5 = lm(y ~ x1 + x2 + x3 + x4 + x5, data = train_data)
  model_6 = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6, data = train_data)
  model_7 = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7, data = train_data)
  model_8 = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8, data = train_data)
  model_9 = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9, data = train_data)
  
  sim1_rmse_train$model_1[iter] = calculate_rmse(train_data$y, predict(model_1, train_data))
  sim1_rmse_train$model_2[iter] = calculate_rmse(train_data$y, predict(model_2, train_data))
  sim1_rmse_train$model_3[iter] = calculate_rmse(train_data$y, predict(model_3, train_data))
  sim1_rmse_train$model_4[iter] = calculate_rmse(train_data$y, predict(model_4, train_data))
  sim1_rmse_train$model_5[iter] = calculate_rmse(train_data$y, predict(model_5, train_data))
  sim1_rmse_train$model_6[iter] = calculate_rmse(train_data$y, predict(model_6, train_data))
  sim1_rmse_train$model_7[iter] = calculate_rmse(train_data$y, predict(model_7, train_data))
  sim1_rmse_train$model_8[iter] = calculate_rmse(train_data$y, predict(model_8, train_data))
  sim1_rmse_train$model_9[iter] = calculate_rmse(train_data$y, predict(model_9, train_data))
  
  sim1_rmse_test$model_1[iter] = calculate_rmse(test_data$y, predict(model_1, test_data))
  sim1_rmse_test$model_2[iter] = calculate_rmse(test_data$y, predict(model_2, test_data))
  sim1_rmse_test$model_3[iter] = calculate_rmse(test_data$y, predict(model_3, test_data))
  sim1_rmse_test$model_4[iter] = calculate_rmse(test_data$y, predict(model_4, test_data))
  sim1_rmse_test$model_5[iter] = calculate_rmse(test_data$y, predict(model_5, test_data))
  sim1_rmse_test$model_6[iter] = calculate_rmse(test_data$y, predict(model_6, test_data))
  sim1_rmse_test$model_7[iter] = calculate_rmse(test_data$y, predict(model_7, test_data))
  sim1_rmse_test$model_8[iter] = calculate_rmse(test_data$y, predict(model_8, test_data))
  sim1_rmse_test$model_9[iter] = calculate_rmse(test_data$y, predict(model_9, test_data))
}

sim2_rmse_train = data.frame(model_1 = rep(0, simulations), model_2 = rep(0, simulations), model_3 = rep(0, simulations),
                             model_4 = rep(0, simulations), model_5 = rep(0, simulations), model_6 = rep(0, simulations),
                             model_7 = rep(0, simulations), model_8 = rep(0, simulations), model_9 = rep(0, simulations))

sim2_rmse_test = data.frame(model_1 = rep(0, simulations), model_2 = rep(0, simulations), model_3 = rep(0, simulations),
                            model_4 = rep(0, simulations), model_5 = rep(0, simulations), model_6 = rep(0, simulations),
                            model_7 = rep(0, simulations), model_8 = rep(0, simulations), model_9 = rep(0, simulations))

for (iter in 1:simulations) {
  eps = rnorm(n, mean = 0, sd = sigma[2])
  study_2_data$y = beta_0 + beta_1 * x1 +  beta_2 * x2 + beta_3 * x3 + beta_4 * x4 + beta_5 * x5 + beta_6 * x6 + eps
  
  train_index = sample(n / 2)
  train_data = study_2_data[train_index,]
  test_data = study_2_data[-train_index,]
  
  model_1 = lm(y ~ x1, data = train_data)
  model_2 = lm(y ~ x1 + x2, data = train_data)
  model_3 = lm(y ~ x1 + x2 + x3, data = train_data)
  model_4 = lm(y ~ x1 + x2 + x3 + x4, data = train_data)
  model_5 = lm(y ~ x1 + x2 + x3 + x4 + x5, data = train_data)
  model_6 = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6, data = train_data)
  model_7 = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7, data = train_data)
  model_8 = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8, data = train_data)
  model_9 = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9, data = train_data)
  
  
  sim2_rmse_train$model_1[iter] = calculate_rmse(train_data$y, predict(model_1, train_data))
  sim2_rmse_train$model_2[iter] = calculate_rmse(train_data$y, predict(model_2, train_data))
  sim2_rmse_train$model_3[iter] = calculate_rmse(train_data$y, predict(model_3, train_data))
  sim2_rmse_train$model_4[iter] = calculate_rmse(train_data$y, predict(model_4, train_data))
  sim2_rmse_train$model_5[iter] = calculate_rmse(train_data$y, predict(model_5, train_data))
  sim2_rmse_train$model_6[iter] = calculate_rmse(train_data$y, predict(model_6, train_data))
  sim2_rmse_train$model_7[iter] = calculate_rmse(train_data$y, predict(model_7, train_data))
  sim2_rmse_train$model_8[iter] = calculate_rmse(train_data$y, predict(model_8, train_data))
  sim2_rmse_train$model_9[iter] = calculate_rmse(train_data$y, predict(model_9, train_data))
  
  sim2_rmse_test$model_1[iter] = calculate_rmse(test_data$y, predict(model_1, test_data))
  sim2_rmse_test$model_2[iter] = calculate_rmse(test_data$y, predict(model_2, test_data))
  sim2_rmse_test$model_3[iter] = calculate_rmse(test_data$y, predict(model_3, test_data))
  sim2_rmse_test$model_4[iter] = calculate_rmse(test_data$y, predict(model_4, test_data))
  sim2_rmse_test$model_5[iter] = calculate_rmse(test_data$y, predict(model_5, test_data))
  sim2_rmse_test$model_6[iter] = calculate_rmse(test_data$y, predict(model_6, test_data))
  sim2_rmse_test$model_7[iter] = calculate_rmse(test_data$y, predict(model_7, test_data))
  sim2_rmse_test$model_8[iter] = calculate_rmse(test_data$y, predict(model_8, test_data))
  sim2_rmse_test$model_9[iter] = calculate_rmse(test_data$y, predict(model_9, test_data))
}

sim3_rmse_train = data.frame(model_1 = rep(0, simulations), model_2 = rep(0, simulations), model_3 = rep(0, simulations),
                             model_4 = rep(0, simulations), model_5 = rep(0, simulations), model_6 = rep(0, simulations),
                             model_7 = rep(0, simulations), model_8 = rep(0, simulations), model_9 = rep(0, simulations))

sim3_rmse_test = data.frame(model_1 = rep(0, simulations), model_2 = rep(0, simulations), model_3 = rep(0, simulations),
                            model_4 = rep(0, simulations), model_5 = rep(0, simulations), model_6 = rep(0, simulations),
                            model_7 = rep(0, simulations), model_8 = rep(0, simulations), model_9 = rep(0, simulations))

for (iter in 1:simulations) {
  eps = rnorm(n, mean = 0, sd = sigma[3])
  study_2_data$y = beta_0 + beta_1 * x1 +  beta_2 * x2 + beta_3 * x3 + beta_4 * x4 + beta_5 * x5 + beta_6 * x6 + eps
  
  train_index = sample(n / 2)
  train_data = study_2_data[train_index,]
  test_data = study_2_data[-train_index,]
  
  model_1 = lm(y ~ x1, data = train_data)
  model_2 = lm(y ~ x1 + x2, data = train_data)
  model_3 = lm(y ~ x1 + x2 + x3, data = train_data)
  model_4 = lm(y ~ x1 + x2 + x3 + x4, data = train_data)
  model_5 = lm(y ~ x1 + x2 + x3 + x4 + x5, data = train_data)
  model_6 = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6, data = train_data)
  model_7 = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7, data = train_data)
  model_8 = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8, data = train_data)
  model_9 = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9, data = train_data)
  
  
  
  sim3_rmse_train$model_1[iter] = calculate_rmse(train_data$y, predict(model_1, train_data))
  sim3_rmse_train$model_2[iter] = calculate_rmse(train_data$y, predict(model_2, train_data))
  sim3_rmse_train$model_3[iter] = calculate_rmse(train_data$y, predict(model_3, train_data))
  sim3_rmse_train$model_4[iter] = calculate_rmse(train_data$y, predict(model_4, train_data))
  sim3_rmse_train$model_5[iter] = calculate_rmse(train_data$y, predict(model_5, train_data))
  sim3_rmse_train$model_6[iter] = calculate_rmse(train_data$y, predict(model_6, train_data))
  sim3_rmse_train$model_7[iter] = calculate_rmse(train_data$y, predict(model_7, train_data))
  sim3_rmse_train$model_8[iter] = calculate_rmse(train_data$y, predict(model_8, train_data))
  sim3_rmse_train$model_9[iter] = calculate_rmse(train_data$y, predict(model_9, train_data))
  
  sim3_rmse_test$model_1[iter] = calculate_rmse(test_data$y, predict(model_1, test_data))
  sim3_rmse_test$model_2[iter] = calculate_rmse(test_data$y, predict(model_2, test_data))
  sim3_rmse_test$model_3[iter] = calculate_rmse(test_data$y, predict(model_3, test_data))
  sim3_rmse_test$model_4[iter] = calculate_rmse(test_data$y, predict(model_4, test_data))
  sim3_rmse_test$model_5[iter] = calculate_rmse(test_data$y, predict(model_5, test_data))
  sim3_rmse_test$model_6[iter] = calculate_rmse(test_data$y, predict(model_6, test_data))
  sim3_rmse_test$model_7[iter] = calculate_rmse(test_data$y, predict(model_7, test_data))
  sim3_rmse_test$model_8[iter] = calculate_rmse(test_data$y, predict(model_8, test_data))
  sim3_rmse_test$model_9[iter] = calculate_rmse(test_data$y, predict(model_9, test_data))
}
```

###  **Results**
###  **Discussion**

## Simulation Study 3: Power

###  **Introduction**
<br />
In this Simulation Study we will be looking at **power** on a simple linear regression test of the following
<br />
<br />
<center>
$H_0: \beta_1 = 0\: vs\: H_1: \ne 0$
</center>
<br />

We define **power** as the probability of reject the null hypothesis when the null is not true or can be written as $P[Reject \: H_0| H_1 \: True]$. In order to test this with simulation we will simulate

\[Y_i = \beta_0 + \beta_1 x_{1i}+ \epsilon_i\]

  -  $\beta_0 = 0$
  -  $\beta_1 \in (-2, -1.9, ..., 1.9, 2)$
  -  $\epsilon_i \sim N(0, \sigma^2)$ where $\sigma \in (1, 2, 4)$
  
For this we will also use a variable sample size of $n \in (10, 20, 30)$, but for our test we will hold $\alpha = 0.05$ for testing our $p-value$ we generate from simulating $1,000$ times. At the end we will look at how **power** changes depending on $beta_1$, $n$, and $\sigma$.

###  **Methods**
```{r setup_power_values, cache=TRUE}
birthday = 19890927
set.seed(birthday)
beta_0 = 0
beta_1_list = seq(-2, 2, .1)
sigmas = c(1, 2, 4)
samples = c(10, 20, 30)
alpha = 0.05
simulations = 1000
number_iterations = length(sigmas) * length(samples) * length(beta_1_list)
power_data = data.frame(sigma = rep(0, number_iterations), n = rep(0, number_iterations),
                        beta_1 = rep(0, number_iterations), power = rep(0, number_iterations))
```
```{r simulate_power, cache=TRUE}
i = 1
for (sigma in sigmas) {
  for (n in samples) {
    x_values = seq(0, 5, length = n)
    for (beta_1 in beta_1_list) {
      rejected = 0
      for (iter in 1:simulations) {
        eps = rnorm(n, 0, sigma)
        y = beta_0 + beta_1 * x_values + eps
        model = lm(y ~ x_values)
        beta_1_p = summary(model)$coefficients[2, 4]
        if (beta_1_p < alpha) {
          rejected = rejected + 1
        }
      }
      power = rejected / simulations
      power_data$sigma[i] = sigma
      power_data$n[i] = n
      power_data$beta_1[i] = beta_1
      power_data$power[i] = power
      i = i + 1
    }
  }
}
```
```{r calculate_mean_sigma, cache=TRUE}
mean_sigmas = rep(0, length(sigmas))
i = 1
for (sigma in sigmas) {
  mean_sigmas[i] = mean(power_data$power[power_data$sigma == sigma])
  i = i + 1
}
```
```{r calculate_mean_beta_1, cache=TRUE}
mean_beta_1s = rep(0, length(beta_1_list))
i = 1
for (beta_1 in beta_1_list) {
  mean_beta_1s[i] = mean(power_data$power[power_data$beta_1 == beta_1])
  i = i + 1
}
```
```{r calculate_mean_sample_size, cache=TRUE}
mean_n = rep(0, length(samples))
i = 1
for (sample in samples) {
  mean_n[i] = mean(power_data$power[power_data$n == sample])
  i = i + 1
}
```


###  **Results**
###  **Discussion**